{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d9dc3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55440fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "from datetime import timedelta, datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "from numpyencoder import NumpyEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f3baeb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ticket_processing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nd/pgsq9c7134jfmgn899bxhdjc0000gn/T/ipykernel_4737/2870344557.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mticket_processing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_gen_support\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mticket_processing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield_options\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ticket_processing'"
     ]
    }
   ],
   "source": [
    "from ticket_processing.data_gen_support import *\n",
    "from ticket_processing.field_options import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b26ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000 # number of tickets\n",
    "o = \"activities.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0abda079",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d2afcd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff201bd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Options for a number of fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f202819",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# As per assessment details\n",
    "status_list = [\"Open\",\"Closed\",\"Resolved\",\"Waiting for Customer\",\"Waiting for Third Party\",\"Pending\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc3fc00",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Properties as per freshdesk website \n",
    "# https://support.freshdesk.com/en/support/solutions/articles/226460-export-ticket-activities-from-your-helpdesk\n",
    "\n",
    "activity_note_types = {0:\"Reply\",\n",
    "                       1:\"Forward\",\n",
    "                       2:\"Reply_to_forward\",\n",
    "                       3:\"Private_note\",\n",
    "                       4:\"Public_note\",\n",
    "                       5:\"Phone_note\",\n",
    "                       6:\"Broadcast_note\"}\n",
    "\n",
    "activity_sources = {1:\"Email\",\n",
    "                    2:\"Portal\",\n",
    "                    3:\"Phone\",\n",
    "                    4:\"Forums\",\n",
    "                    5:\"Twitter\",\n",
    "                    6:\"Facebook\",\n",
    "                    7:\"Chat\",\n",
    "                    8:\"Mobihelp\",\n",
    "                    9:\"Feedback widget\",\n",
    "                    10:\"Outbound email\",  \n",
    "                    11:\"E-commerce\",\n",
    "                    12: \"Bot\"  }\n",
    "\n",
    "activity_priorities = {1:\"Low\",\n",
    "                       2:\"Medium\",\n",
    "                       3:\"High\",\n",
    "                       4:\"Urgent\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c5af224",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "products = {\n",
    "            'phone':['mobile','landline phone'],\n",
    "            'tablets':['Apple','Samsung'],\n",
    "            'computer': ['laptop','desktop PC'],\n",
    "            'headphones': ['earphones','headphones']\n",
    "}\n",
    "issue_types = {\n",
    "                \"Pre_Sale_Question\": ['question'],\n",
    "                \"Order_Question\": ['question'],\n",
    "                \"Return\": ['refund', \"store credit\", \"exchange\"],\n",
    "                \"Shipping\": ['missing', 'delivery delay'],\n",
    "                \"Vendor\": ['stock', 'price'],\n",
    "                \"Accounts\": ['payment','address','login','registration'],\n",
    "                \"Product_Availability\": ['low','not available']\n",
    "                }\n",
    "activity_priorities = [1,1,2,4,4,3,1]\n",
    "performer_ids = np.arange(149015,149020) # assumer there are 5 agents\n",
    "requesters = np.arange(1,n+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a030956b",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9111093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def contact_customer_check(status):\n",
    "#     if status in [\"Closed\",\"Resolved\",\"Waiting for Customer\"]:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return random.choice([True, False])\n",
    "\n",
    "# def generate_ticket_ids(n, max_repeat):\n",
    "#     '''\n",
    "#     Return a numpy array of ticket ids based on the number of tickets (n) required\n",
    "#     Ticket IDs can be repeated but not more than the input max_repeat\n",
    "#     '''\n",
    "#     ticket_ids_options = np.arange(1,n+1)\n",
    "#     ticket_ids = np.random.choice(ticket_ids_options,size=n) # generate ticket ids\n",
    "#     dup_flag = 1\n",
    "#     while dup_flag == 1:\n",
    "#         ticket_uniques, unique_counts = np.unique(ticket_ids, return_counts=True) # get unique values and number of occurences\n",
    "\n",
    "#         # one ticket_id cannot have more than 6 activities\n",
    "#         if unique_counts.max() <= max_repeat: # if no value is repeated more than 6 times\n",
    "#             dup_flag = 0\n",
    "#         else: # need to re-generate those\n",
    "#             # find ticket_numbers with more than 6 occurences\n",
    "#             to_resample = ticket_uniques[np.argwhere(unique_counts > max_repeat)]\n",
    "\n",
    "#             # remove values with more than 5 occurences from sampling population\n",
    "#             to_remove = ticket_uniques[np.argwhere(unique_counts >= max_repeat)]\n",
    "#             ticket_ids_options = np.delete(ticket_ids_options,to_remove - 1)\n",
    "\n",
    "#             # for each value in to_resample, get indices in ticket_ids to resample\n",
    "#             idx_ticket_ids_to_resample = [np.where(ticket_ids == x)[0] for x in to_resample]\n",
    "#             idx_ticket_ids_to_resample = np.concatenate([np.delete(a,list(range(0,max_repeat))) \n",
    "#                                                          for a in idx_ticket_ids_to_resample])\n",
    "\n",
    "#             # update ticket_ids\n",
    "#             for i in idx_ticket_ids_to_resample:\n",
    "#                 ticket_ids[i] = np.random.choice(ticket_ids_options)\n",
    "                \n",
    "#     return ticket_ids\n",
    "    \n",
    "\n",
    "# def generate_status(ticket_ids,status_list):\n",
    "#     '''\n",
    "#     Return a numpy array of statuses based on input ticket_ids array\n",
    "#     Tickets of the same ids will have different status\n",
    "#     '''\n",
    "#     status = np.empty(shape= ticket_ids.shape, dtype=object)\n",
    "#     ticket_uniques, ticket_counts = np.unique(ticket_ids, return_counts=True)\n",
    "\n",
    "#     # for tickets of the same id, allocate none repeated status\n",
    "#     ticket_dupes = ticket_uniques[np.where(ticket_counts > 1)]\n",
    "#     idx_ticket_dupes = np.concatenate([np.where(ticket_ids == x)[0] for x in ticket_dupes])\n",
    "#     status_dupes = np.concatenate([random.sample(status_list,count) \n",
    "#                                    for count in ticket_counts[np.where(ticket_counts > 1)]])\n",
    "#     status[idx_ticket_dupes] = status_dupes\n",
    "\n",
    "#     # for ticket_ids appearing only once, randomly choose a status from status list\n",
    "#     ticket_single = ticket_uniques[np.where(ticket_counts == 1)]\n",
    "#     idx_ticket_single = np.concatenate([np.where(ticket_ids == x)[0] for x in ticket_single])\n",
    "#     status_single = np.random.choice(status_list,len(ticket_single))\n",
    "#     status[idx_ticket_single] = status_single\n",
    "    \n",
    "#     return status\n",
    "\n",
    "# def get_priority(issue_type):\n",
    "#     '''\n",
    "#     Return ticket priority based on issue_type\n",
    "#     '''\n",
    "#     return activity_priorities[list(issue_types.keys()).index(issue_type)]\n",
    "\n",
    "# def transform_unique_array(unique_field,ticket_id):\n",
    "#     '''\n",
    "#     Transform array with per-unique-ticket values to array corresponding to ticket ID\n",
    "#     '''\n",
    "#     # generate empty output array of same shape as ticket_ids\n",
    "#     output = np.empty(shape=ticket_id.shape,dtype = unique_field.dtype)\n",
    "\n",
    "#     # group ticket_ids indices based on ticket_id value\n",
    "#     ticket_uniques, unique_counts = np.unique(ticket_id,return_counts=True)\n",
    "#     idx_ticket_ids = [np.where(ticket_id == x)[0] for x in ticket_uniques]\n",
    "\n",
    "#     # assign value to output\n",
    "#     for j,idx in enumerate(idx_ticket_ids):\n",
    "#         output[idx] = unique_field[j]\n",
    "#     return output\n",
    "\n",
    "# def fake_time_long_format(start_date_dt, end_date_dt):\n",
    "#     '''\n",
    "#     Return a fake date between input start date and end date.\n",
    "#     Both inputs must be of type datetime\n",
    "#     Output in string, format e.g. '28-11-2022 12:05:37 +0000'\n",
    "#     '''\n",
    "#     fake = Faker()\n",
    "#     fake_date_dt = fake.date_time_between(start_date=start_date_dt, end_date=end_date_dt)\n",
    "#     return \" \".join([dt.strftime(fake_date_dt, \"%d-%m-%Y %H:%M:%S\"), \"+0000\"])\n",
    "\n",
    "# # function to create timestamp for each ticket\n",
    "# def get_time_from_status(status,metadata):\n",
    "#     '''\n",
    "#     Input is an array of status for one ticket\n",
    "#     Output is a numpy array of correspoding timestamp based on status\n",
    "#     '''\n",
    "#     # generate empty array of same shape as status\n",
    "#     output = np.empty(shape = status.shape,dtype = object)\n",
    "    \n",
    "#     # convert metadata start and end dates to datetime format\n",
    "#     end_date_dt = dt.strptime(metadata['metadata']['end_at'],\"%d-%m-%Y %H:%M:%S %z\")\n",
    "#     start_date_dt = dt.strptime(metadata['metadata']['start_at'],\"%d-%m-%Y %H:%M:%S %z\")\n",
    "    \n",
    "#     # closed status corresponds to latest timestamp\n",
    "#     if \"Closed\" in status:\n",
    "#         idx = np.argwhere(status =='Closed')[0][0] # idx type = integer\n",
    "#         output[idx] = fake_time_long_format(start_date_dt + timedelta(hours = 6),end_date_dt) # string format\n",
    "#         end_date_dt = dt.strptime(output[idx],\"%d-%m-%Y %H:%M:%S %z\") \n",
    "    \n",
    "#     # resolved corresponds to latest or 2nd latest timestamp\n",
    "#     if \"Resolved\" in status:\n",
    "#         idx = np.argwhere(status =='Resolved')[0][0] # idx type = integer\n",
    "#         output[idx] = fake_time_long_format(start_date_dt + timedelta(hours = 2),end_date_dt) # string format\n",
    "#         end_date_dt = dt.strptime(output[idx],\"%d-%m-%Y %H:%M:%S %z\") \n",
    "    \n",
    "#     # for other status, generate a random timestamp\n",
    "#     remaining_status = np.setdiff1d(status,np.array(['Closed','Resolved']))\n",
    "#     if len(remaining_status) > 0:\n",
    "#         output_idx = np.concatenate([np.where(status == x)[0] for x in remaining_status])\n",
    "#         output[output_idx] = [fake_time_long_format(start_date_dt,end_date_dt)\n",
    "#                               for i in range(len(remaining_status))]\n",
    "    \n",
    "#     return output\n",
    "        \n",
    "\n",
    "# def get_single_ship_date(metadata):\n",
    "#     end_date = dt.strptime(metadata['metadata']['start_at'],\"%d-%m-%Y %H:%M:%S %z\")\n",
    "#     start_date = \"\".join([\"-\",str(np.random.randint(0,14,1)[0]),\"d\"])\n",
    "#     return dt.strftime(fake.date_time_between(start_date=start_date, end_date=end_date),\n",
    "#                    '%d %b,%Y')\n",
    "\n",
    "# def get_tickets_with_notes(ticket_id):\n",
    "#     '''\n",
    "#     Randomly choose a small number of ticket ids and assign a note to it.\n",
    "#     Any ticket containing a note will not have other fields\n",
    "#     Return:\n",
    "#     - list of notes for the number of choosen tickets\n",
    "#     - list of ticket ID indices (in input ticket id array) where a note will be created\n",
    "#     '''\n",
    "#     ticket_uniques, unique_counts = np.unique(ticket_id,return_counts=True)\n",
    "\n",
    "#     # randomly choose some ticket ids with notes only\n",
    "#     ticketID_note_pop = ticket_uniques[np.where(unique_counts ==1)[0]]\n",
    "#     choose_random_note = random.choices([1,0],weights=[10,90],\n",
    "#                                         k = len(ticketID_note_pop)) # if random no. = 1, ticket with notes, else no note\n",
    "#     ticketID_w_notes = ticketID_note_pop * choose_random_note\n",
    "#     ticketID_w_notes = ticketID_w_notes[ticketID_w_notes != 0] # remove zero\n",
    "\n",
    "#     # generate note for the choosen ticket ids\n",
    "#     note_id = np.random.randint(1000000,9999999,len(ticketID_w_notes))\n",
    "#     note_type = np.random.randint(0,7,len(ticketID_w_notes))\n",
    "#     note = [{\n",
    "#         \"id\": x,\n",
    "#         \"type\": y\n",
    "#     } for x,y in zip (note_id,note_type)]\n",
    "\n",
    "#     idx_ticketID_w_notes = np.concatenate([np.where(ticket_id == x)[0] for x in ticketID_w_notes]).tolist()\n",
    "    \n",
    "#     return note, idx_ticketID_w_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8fc104",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e052c",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "210963ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'start_at': '28-11-2022 10:15:26 +0000',\n",
       "  'end_at': '29-11-2022 10:15:26 +0000',\n",
       "  'activities_count': 1000}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#============= generate metadata =============\n",
    "metadata = {\"metadata\": {\"start_at\": \" \".join([dt.strftime(dt.now() + timedelta(days = -1),\"%d-%m-%Y %H:%M:%S\"),\"+0000\"]),\n",
    "                         \"end_at\" : \" \".join([dt.strftime(dt.now(),\"%d-%m-%Y %H:%M:%S\"),\"+0000\"]), # assume extract ticket at set time\n",
    "                         'activities_count' : n}}\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81165c57",
   "metadata": {},
   "source": [
    "### Activities_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a32ca5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Generate Ticket IDs and Associated Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "366262f8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ticket_ids_test = generate_ticket_ids(100,4)\n",
    "test_uniques, test_counts = np.unique(ticket_ids_test, return_counts=True)\n",
    "assert len(ticket_ids_test) == 100\n",
    "assert test_counts.max() <= 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc5f304a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#============= generate ticket ids =============\n",
    "ticket_id = generate_ticket_ids(n,len(status_list))\n",
    "ticket_uniques, unique_counts = np.unique(ticket_id,return_counts=True)\n",
    "idx_ticket_ids = [np.where(ticket_id == x)[0] for x in ticket_uniques]\n",
    "\n",
    "#============= generate ticket status =============\n",
    "status = generate_status(ticket_id, status_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1362093a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#============= generate performed_at timestamp =============\n",
    "# get array of status for each unique ticket\n",
    "status_p_ticket = [status[idx] for idx in idx_ticket_ids] # list of arrays\n",
    "timestamps_p_ticket = np.concatenate([get_time_from_status(x,metadata) for x in status_p_ticket])\n",
    "\n",
    "performed_at = transform_unique_array(timestamps_p_ticket,ticket_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dc9156",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Generate generic fields for each unique ticket ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaa2fe3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "for the same ticket_ids, the following should be the same and can be generated together\n",
    "[\"ticket_id\",\"performer_type\",\"performer_id\",\"shipping_address\",\"shipment_date\",\n",
    " \"category\",\"issue_type\",\"source\",\"priority\",\"group\",\"agent_id\",\"requester\",\"product\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00467981",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# generate fields for each unique ticket ID\n",
    "performer_type = np.array(['user']*len(ticket_uniques))\n",
    "assert len(performer_type) == len(ticket_uniques)\n",
    "performer_id = np.random.choice(performer_ids,len(ticket_uniques),replace=True)\n",
    "assert len(performer_id) == len(ticket_uniques)\n",
    "shipping_address = np.array(['N/A']*len(ticket_uniques))\n",
    "category = np.random.choice(list(products.keys()),len(ticket_uniques),replace=True)\n",
    "issue_type = np.random.choice(list(issue_types.keys()),len(ticket_uniques),replace=True)\n",
    "assert len(issue_type) == len(ticket_uniques)\n",
    "source = np.random.randint(1,12+1,size = len(ticket_uniques))\n",
    "assert len(source) == len(ticket_uniques)\n",
    "# priority based on issue_type\n",
    "priority = np.array([get_priority(x) for x in issue_type]) # based on issue_type\n",
    "assert len(priority) == len(ticket_uniques)\n",
    "group = np.concatenate([np.random.choice(issue_types[k],1) for k in issue_type]) # based on issue_type\n",
    "assert len(group) == len(ticket_uniques)\n",
    "agent_id = performer_id\n",
    "requester = np.random.choice(requesters,len(ticket_uniques),replace=True)\n",
    "assert len(requester) == len(ticket_uniques)\n",
    "product = np.concatenate([np.random.choice(products[k],1) for k in category]) # based on category\n",
    "assert len(product) == len(ticket_uniques)\n",
    "# shipment date depends on issue type\n",
    "shipment_date_p_ticket = np.empty(ticket_uniques.shape,object)\n",
    "idx = np.where((issue_type == 'Return') | (issue_type == 'Shipping'))[0]\n",
    "shipment_date_p_ticket[idx] = [get_single_ship_date(metadata) for i in range(len(idx))]\n",
    "assert len(shipment_date_p_ticket) == len(ticket_uniques)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcf26ffd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "performer_type = transform_unique_array(performer_type, ticket_id)\n",
    "performer_id = transform_unique_array(performer_id, ticket_id)\n",
    "shipping_address = transform_unique_array(shipping_address, ticket_id)\n",
    "category = transform_unique_array(category, ticket_id)\n",
    "issue_type = transform_unique_array(issue_type, ticket_id)\n",
    "source = transform_unique_array(source, ticket_id)\n",
    "priority = transform_unique_array(priority, ticket_id)\n",
    "group = transform_unique_array(group, ticket_id)\n",
    "agent_id = transform_unique_array(agent_id, ticket_id)\n",
    "requester = transform_unique_array(requester, ticket_id)\n",
    "product = transform_unique_array(product, ticket_id)\n",
    "shipment_date = transform_unique_array(shipment_date_p_ticket, ticket_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "719ff3fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "contacted_customer = np.array([contact_customer_check(x) for x in status])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43e37ede",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#============ check if data generated successfully ============\n",
    "assert len(performer_id) == len(ticket_id)\n",
    "assert len(shipping_address) == len(ticket_id)\n",
    "assert len(category) == len(ticket_id)\n",
    "assert len(issue_type) == len(ticket_id)\n",
    "assert len(performer_type) == len(ticket_id)\n",
    "assert len(source) == len(ticket_id)\n",
    "assert len(priority) == len(ticket_id)\n",
    "assert len(group) == len(ticket_id)\n",
    "assert len(agent_id) == len(ticket_id)\n",
    "assert len(requester) == len(ticket_id)\n",
    "assert len(product) == len(ticket_id)\n",
    "assert len(shipment_date) == len(ticket_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a49cc6b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# [performed_at,ticket_id ,performer_type,performer_id,shipping_address,shipment_date,\n",
    "# category,contacted_customer,issue_type,source,status,priority,group,agent_id,requester,product]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f07b54",
   "metadata": {},
   "source": [
    "#### Generate notes with id and note type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c75916",
   "metadata": {},
   "source": [
    "- Apply for ticket ids with one occurence only\n",
    "- Randomly choose only a few of those\n",
    "- Where there's a note, no other information is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "278e18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "note, idx_ticketID_w_notes = get_tickets_with_notes(ticket_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f91679",
   "metadata": {},
   "source": [
    "### Generate json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16ce73e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_data = []\n",
    "for i in range(len(ticket_id)):\n",
    "    activities_data.append({\n",
    "                                \"performed_at\":performed_at[i],\n",
    "                                \"ticket_id\":ticket_id[i],\n",
    "                                \"performer_type\":performer_type[i],\n",
    "                                \"performer_id\":performer_id[i],\n",
    "                                \"activity\":{\n",
    "                                    \"shipping_address\":shipping_address[i],\n",
    "                                    \"shipment_date\":shipment_date[i],\n",
    "                                    \"category\":category[i],\n",
    "                                    \"contacted_customer\":contacted_customer[i],\n",
    "                                    \"issue_type\":issue_type[i],\n",
    "                                    \"source\":source[i],\n",
    "                                    \"status\":status[i],\n",
    "                                    \"priority\":priority[i],\n",
    "                                    \"group\":group[i],\n",
    "                                    \"agent_id\":agent_id[i],\n",
    "                                    \"requester\":requester[i],\n",
    "                                    \"product\":product[i]\n",
    "                                }\n",
    "                            })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df1d20f",
   "metadata": {},
   "source": [
    "- for each activity data:\n",
    "- drop shipment date if it's none\n",
    "- drop a number of fields\n",
    "- change a few to notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53c2744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,data in enumerate(activities_data):\n",
    "    # add notes and remove other fields where notes are generated\n",
    "    if i in idx_ticketID_w_notes:\n",
    "        del data['activity']\n",
    "        data['activity'] = {\"note\": note[idx_ticketID_w_notes.index(i)]}\n",
    "    \n",
    "    # remove shipment_date and shipment_address fields where value is None\n",
    "    else:\n",
    "        if data['activity']['shipment_date']== None:\n",
    "            del data['activity']['shipment_date']\n",
    "            del data['activity']['shipping_address']\n",
    "\n",
    "        # if ticket has to do with Vendor, remove contact customer\n",
    "        if data['activity']['issue_type']== 'Vendor':\n",
    "            del data['activity']['contacted_customer'] \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a92efadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'performed_at': '28-11-2022 18:23:56 +0000',\n",
       " 'ticket_id': 249,\n",
       " 'performer_type': 'user',\n",
       " 'performer_id': 149016,\n",
       " 'activity': {'note': {'id': 8765303, 'type': 5}}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities_data[idx_ticketID_w_notes[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51f739c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final = metadata.copy()\n",
    "final.update({\"activities_data\": activities_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dd74eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(o,'w') as outfile:\n",
    "    json.dump(final,outfile,cls=NumpyEncoder,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9febc080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7743f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(r\"data\") == False:\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3485f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
