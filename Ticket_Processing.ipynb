{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eadf9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "68b9c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nested_json(df):\n",
    "    col_list = []\n",
    "    \n",
    "    for name in df.schema.names:\n",
    "        # if item is structtype, then get field names inside item\n",
    "        if isinstance(df.schema[name].dataType, StructType):\n",
    "            for field in df.schema[name].dataType.fields:\n",
    "#                 col_list.append(col(\".\".join([name,field.name])).alias(\"_\".join([name,field.name])))\n",
    "                col_list.append(col(\".\".join([name,field.name])).alias(field.name))      \n",
    "                \n",
    "        # if item is Array type, then make new df and explode/separate array\n",
    "        elif isinstance(df.schema[name].dataType, ArrayType):\n",
    "            df = df.withColumn(name,explode(name).alias(name))\n",
    "            col_list.append(name)\n",
    "        # if other types, then just add\n",
    "        else:\n",
    "            col_list.append(name)\n",
    "    df = df.select(col_list)\n",
    "    return df\n",
    "\n",
    "def correct_time_string(time_string):\n",
    "    try:\n",
    "        return time_string[:-2]+ \":\" + time_string[-2:]\n",
    "    except:\n",
    "        return time_string\n",
    "    \n",
    "assert correct_time_string(\"20-04-2017 10:00:00 +0000\") == \"20-04-2017 10:00:00 +00:00\"\n",
    "\n",
    "def convert_to_timestamp(df,col_list):\n",
    "    correct_tz_UDF = udf(lambda z:correct_time_string(z)) \n",
    "    for col_name in col_list:\n",
    "        df = df.withColumn(col_name,correct_tz_UDF(col(col_name)))\n",
    "        df = df.withColumn(col_name,to_timestamp(col_name,format = \"dd-MM-yyyy HH:mm:ss z\"))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2d01ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/27 13:21:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('ticket_processing').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08bd7372",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"example.json\"\n",
    "with open(json_path) as json_file:\n",
    "    json_dict = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f30c7b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- activities_data: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- activity: struct (nullable = true)\n",
      " |    |    |    |-- agent_id: long (nullable = true)\n",
      " |    |    |    |-- category: string (nullable = true)\n",
      " |    |    |    |-- contacted_customer: boolean (nullable = true)\n",
      " |    |    |    |-- group: string (nullable = true)\n",
      " |    |    |    |-- issue_type: string (nullable = true)\n",
      " |    |    |    |-- note: struct (nullable = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- type: long (nullable = true)\n",
      " |    |    |    |-- priority: long (nullable = true)\n",
      " |    |    |    |-- product: string (nullable = true)\n",
      " |    |    |    |-- requester: long (nullable = true)\n",
      " |    |    |    |-- shipment_date: string (nullable = true)\n",
      " |    |    |    |-- shipping_address: string (nullable = true)\n",
      " |    |    |    |-- source: long (nullable = true)\n",
      " |    |    |    |-- status: string (nullable = true)\n",
      " |    |    |-- performed_at: string (nullable = true)\n",
      " |    |    |-- performer_id: long (nullable = true)\n",
      " |    |    |-- performer_type: string (nullable = true)\n",
      " |    |    |-- ticket_id: long (nullable = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- activities_count: long (nullable = true)\n",
      " |    |-- end_at: string (nullable = true)\n",
      " |    |-- start_at: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read json as rawfile\n",
    "df_json = spark.read.json(json_path, multiLine= True)\n",
    "df_json.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "050def51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- agent_id: long (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- contacted_customer: boolean (nullable = true)\n",
      " |-- group: string (nullable = true)\n",
      " |-- issue_type: string (nullable = true)\n",
      " |-- note: struct (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |-- priority: long (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- requester: long (nullable = true)\n",
      " |-- shipment_date: date (nullable = true)\n",
      " |-- shipping_address: string (nullable = true)\n",
      " |-- source: long (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- performed_at: timestamp (nullable = true)\n",
      " |-- performer_id: long (nullable = true)\n",
      " |-- performer_type: string (nullable = true)\n",
      " |-- ticket_id: long (nullable = true)\n",
      "\n",
      "+---------+-------------------+-------------+\n",
      "|ticket_id|       performed_at|shipment_date|\n",
      "+---------+-------------------+-------------+\n",
      "|      600|2017-04-21 19:03:38|         null|\n",
      "|      704|2017-04-21 19:08:24|   2017-04-21|\n",
      "+---------+-------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract activity data and flatten  dataframe\n",
    "activity_df = df_json.select('activities_data')\n",
    "activity_df = activity_df.withColumn('activities_data',explode('activities_data'))\n",
    "col_list = [\".\".join(['activities_data', field.name]) \\\n",
    "            for field in activity_df.schema['activities_data'].dataType.fields]\n",
    "activity_df = activity_df.select(col_list)\n",
    "activity_df = read_nested_json(activity_df)\n",
    "\n",
    "# convert performed_at and shipment_date to appropriate timestamp format\n",
    "activity_df = convert_to_timestamp(activity_df,['performed_at'])\n",
    "activity_df = activity_df.withColumn('shipment_date',to_date('shipment_date',format = \"dd MMM, yyyy\"))\n",
    "\n",
    "#======================== check outputs ========================\n",
    "assert activity_df.filter(activity_df.performed_at.isNull()).count() == 0\n",
    "activity_df.printSchema()\n",
    "activity_df.select(['ticket_id','performed_at','shipment_date']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f98c1752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- activities_count: long (nullable = true)\n",
      " |-- end_at: timestamp (nullable = true)\n",
      " |-- start_at: timestamp (nullable = true)\n",
      "\n",
      "+----------------+-------------------+-------------------+\n",
      "|activities_count|             end_at|           start_at|\n",
      "+----------------+-------------------+-------------------+\n",
      "|               2|2017-04-21 19:29:59|2017-04-20 19:30:00|\n",
      "+----------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_list = [\".\".join(['metadata',field.name]) for field in df_json.schema['metadata'].dataType.fields]\n",
    "metadata_df = df_json.select(col_list)\n",
    "to_convert_list = ['start_at','end_at']\n",
    "metadata_df = convert_to_timestamp(metadata_df,to_convert_list)\n",
    "metadata_df.printSchema()\n",
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "41efc5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+-------------------+---------------+\n",
      "|activities_count|             end_at|           start_at|time_delta_mins|\n",
      "+----------------+-------------------+-------------------+---------------+\n",
      "|               2|2017-04-21 19:29:59|2017-04-20 19:30:00|         1440.0|\n",
      "+----------------+-------------------+-------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata_df.withColumn('time_delta_mins',\n",
    "                       round((metadata_df.end_at.cast('long') - metadata_df.start_at.cast('long')) / 60,0 )) \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "829d37b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {\"start_at\" : \"20-04-2017 10:00:00\",\n",
    "\"end_at\":  \"21-04-2017 09:59:59\",\n",
    "\"performed_at\": \"21-04-2017 09:38:24\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3e12da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d0d7fffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.583333333333332"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict_dt = {k:dt.strptime(v,\"%d-%m-%Y %H:%M:%S\") for k,v in test_dict.items()}\n",
    "open_time = test_dict_dt['end_at'] - test_dict_dt['performed_at']\n",
    "open_time.total_seconds()/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "98d06280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>performed_at</th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>performer_type</th>\n",
       "      <th>performer_id</th>\n",
       "      <th>note</th>\n",
       "      <th>shipping_address</th>\n",
       "      <th>shipment_date</th>\n",
       "      <th>category</th>\n",
       "      <th>contacted_customer</th>\n",
       "      <th>issue_type</th>\n",
       "      <th>source</th>\n",
       "      <th>status</th>\n",
       "      <th>priority</th>\n",
       "      <th>group</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>requester</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21-04-2017 09:33:38 +0000</td>\n",
       "      <td>600</td>\n",
       "      <td>user</td>\n",
       "      <td>149018</td>\n",
       "      <td>{'id': 4025864, 'type': 4}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21-04-2017 09:38:24 +0000</td>\n",
       "      <td>704</td>\n",
       "      <td>user</td>\n",
       "      <td>149018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>21 Apr, 2017</td>\n",
       "      <td>Phone</td>\n",
       "      <td>True</td>\n",
       "      <td>Incident</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Open</td>\n",
       "      <td>4.0</td>\n",
       "      <td>refund</td>\n",
       "      <td>149018.0</td>\n",
       "      <td>145423.0</td>\n",
       "      <td>mobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                performed_at  ticket_id performer_type  performer_id  \\\n",
       "0  21-04-2017 09:33:38 +0000        600           user        149018   \n",
       "1  21-04-2017 09:38:24 +0000        704           user        149018   \n",
       "\n",
       "                         note shipping_address shipment_date category  \\\n",
       "0  {'id': 4025864, 'type': 4}              NaN           NaN      NaN   \n",
       "1                         NaN              N/A  21 Apr, 2017    Phone   \n",
       "\n",
       "  contacted_customer issue_type  source status  priority   group  agent_id  \\\n",
       "0                NaN        NaN     NaN    NaN       NaN     NaN       NaN   \n",
       "1               True   Incident     3.0   Open       4.0  refund  149018.0   \n",
       "\n",
       "   requester product  \n",
       "0        NaN     NaN  \n",
       "1   145423.0  mobile  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df = pd.DataFrame(json_dict['activities_data'])\n",
    "df_raw = pd.concat([pd_df.drop(columns = ['activity']),pd_df.activity.apply(pd.Series)],\n",
    "                   axis = 1)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08ff9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
